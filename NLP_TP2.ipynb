{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OcJFxMQW0055",
        "RhteY6rf1aqZ",
        "qwIHyMlL1d2x"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP - TP Nº 2 - Chatbot - RAG"
      ],
      "metadata": {
        "id": "AEOZnAvmzLFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción"
      ],
      "metadata": {
        "id": "HwSAVZh-zQSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TUIA - Procesamiento del Lenguaje Natural** - 2023\n",
        "\n",
        "---\n",
        "\n",
        "Trabajo Práctico Nº 2 - \"Chatbots y sistemas de diálogo. Agentes Autónomos\"\n",
        "\n",
        "\n",
        "**Alumno:**\n",
        "\n",
        "* Miguel Mussi"
      ],
      "metadata": {
        "id": "_J9i61CVzTfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pautas Generales"
      ],
      "metadata": {
        "id": "OcJFxMQW0055"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* El trabajo deberá ser realizado individualmente.\n",
        "* Deberá informar cuál es la url del repositorio con el que van a trabajar y las definiciones de en qué problematicas quisieran solucionar con un sistema multiagente en el siguiente formulario:  https://docs.google.com/forms/d/e/1FAIpQLSdOZNGOzQ1gbf43caA4ygAbLx5tm5bU-s8RdfdftOzd_aXzhA/viewform?usp=pp_url\n",
        "* Se debe entregar un informe en el cual se incluya las justificaciones y un vínculo a los archivos que permitan reproducir el proyecto. No se acepta solamente código.\n",
        "* Temas deseables a cubrir en el tp:\n",
        "\n",
        "\n",
        "> * Recuperación de datos de bases de datos de grafos\n",
        "* Extracción de conocimiento de texto y posterior inserción en una base de datos de grafos\n",
        "* Agentes (estará cubierto en el Ejercicio 2)"
      ],
      "metadata": {
        "id": "RkAYHdkn03hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1 - RAG"
      ],
      "metadata": {
        "id": "RhteY6rf1aqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear un chatbot experto en un tema a elección, usando la técnica RAG (Retrieval Augmented Generation). Como fuentes de conocimiento se utilizarán al menos las siguientes fuentes:\n",
        "* Documentos de texto\n",
        "* Datos numéricos en formato tabular (por ej., Dataframes, CSV, sqlite, etc.)\n",
        "* Base de datos de grafos (Online o local)\n",
        "\n",
        "El sistema debe poder llevar a cabo una conversación en lenguaje español. El usuario podrá hacer preguntas, que el chatbot intentará responder a partir de datos de algunas de sus fuentes. El asistente debe poder clasificar las preguntas, para saber qué fuentes de datos utilizar como contexto para generar una respuesta.\n",
        "\n",
        "**Requerimientos generales**\n",
        "\n",
        "* Realizar todo el proyecto en un entorno Google Colab\n",
        "* El conjunto de datos debe tener al menos 100 páginas de texto y un mínimo de 3 documentos.\n",
        "* Realizar split de textos usando Langchain (RecursiveTextSearch, u otros métodos disponibles). Limpiar el texto según sea conveniente.\n",
        "* Realizar los embeddings que permitan vectorizar el texto y almacenarlo en una base de datos ChromaDB\n",
        "* Los modelos de embeddings y LLM para generación de texto son a elección\n",
        "* Para el desarrollo del “Clasificador” es posible utilizar diversas técnicas aprendidas en la materia, por ejemplo en Unidad 3 y Unidad 6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OaAt51aT1mPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2 - Agentes"
      ],
      "metadata": {
        "id": "qwIHyMlL1d2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realice una investigación respecto al estado del arte de las aplicaciones actuales de **agentes inteligentes** usando modelos LLM libres.\n",
        "\n",
        "Plantee una problemática a solucionar con un sistema multiagente. Defina cada uno de los agentes involucrados en la tarea. Es importante destacar con ejemplos de conversación, la interacción entre los agentes.\n",
        "\n",
        "Realice un informe con los resultados de la investigación y con el esquema del sistema multiagente, no olvide incluir fuentes de información.\n",
        "\n",
        "**Opcional**: Resolución con código de dicho escenario."
      ],
      "metadata": {
        "id": "M2KrPWXP1n1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 1"
      ],
      "metadata": {
        "id": "XyeanLeu1o3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elección del Tema y Recopilación de datos"
      ],
      "metadata": {
        "id": "wUg0BXGF17qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El chatbot será especialista en temas relacionados al marco legal de la Educación Argentina, en particular en la provincia de Buenos Aires.\n",
        "\n",
        "Será denominado \"EduArDo\" como una forma de darle un nombre propio que relacione las ideas de \"Educación\", \"Argentina\" y \"Hacer\" (*'do'* en inglés).\n",
        "\n",
        "Para su contexto, se lo proveerá con los siguientes archivos pdf:\n",
        "\n",
        "* Marco Legal de la Educación en la Argentina (21 páginas)\n",
        "* Reglamento General de Escuelas Públicas de la Provincia de Buenos Aires (88 páginas)\n",
        "* Ley de Educación Nacional Nº 26206 (30 páginas)\n",
        "* Estatuto Docente de la Provincia de Buenos Aires (271 páginas)\n",
        "\n",
        "Además, se cargará un dataframe con el Padrón Oficial de Establecimientos Educativos (datos.gob.ar) para consultas sobre datos específicos sobre las instituciones."
      ],
      "metadata": {
        "id": "vKZOkSC02QGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 - Instalación de Librerías"
      ],
      "metadata": {
        "id": "GkJkv_oy3jSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "HWlYejuPLU_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "uhEl5_90LhKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "id": "NJimHyanLprG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "r_U3r6UZLvQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "E-NPuBMhLzwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "Ww3wArgfL2T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "yTB5FwHJL6HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-decouple"
      ],
      "metadata": {
        "id": "KkSedp1jL8bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "DDQOE1vYL-zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "Rd7jOosRMF5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "d8GwgAGtMqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z09yz4pWyMPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Base de datos vectorial"
      ],
      "metadata": {
        "id": "gWbiRoWXyLUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuentes de datos"
      ],
      "metadata": {
        "id": "3nzg86eu2WRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa los archivos de una carpeta específica de drive\n",
        "drive_path = \"/content/drive/MyDrive/UNR/4 - Proc Lenguaje Natural (IA42)/TP2/EduArDo/Data\""
      ],
      "metadata": {
        "id": "-7Y7GDy3hvoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdfplumber as pp\n",
        "\n",
        "# Nombre de los textos cargados en Drive\n",
        "archivos = ['Marco_Legal_Educacion_Argentina',\n",
        "            'Ley_Educacion_Nacional_26206',\n",
        "            'Reglamento_Gral_Escuelas_BsAs',\n",
        "            'Estatuto_Docente_BsAs']\n",
        "\n",
        "# Aca se almacenaran los textos de los pdf\n",
        "textos = {}\n",
        "\n",
        "# Extracción de los pdf:\n",
        "for archivo in archivos:\n",
        "    pdf_path = os.path.join(drive_path, f'{archivo}.pdf')\n",
        "\n",
        "    # Verificamos si el archivo existe antes de intentar abrirlo\n",
        "    if os.path.exists(pdf_path):\n",
        "        # Abrimos el pdf\n",
        "        with pp.open(pdf_path) as pdf:\n",
        "            texto = \"\"\n",
        "            # Por cada página\n",
        "            for pagina in pdf.pages:\n",
        "                # Extraemos el texto\n",
        "                texto += pagina.extract_text() + \"\\n\"\n",
        "            # Una vez que extraemos cada pagina guardamos el texto entero con la clave del nombre correspondiente al archivo\n",
        "            textos[archivo] = texto\n",
        "    else:\n",
        "        print(f\"El archivo {archivo}.pdf no se encuentra en la ruta especificada: {pdf_path}\")\n"
      ],
      "metadata": {
        "id": "XOOnYZjTSlWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(textos['Estatuto_Docente_BsAs'])"
      ],
      "metadata": {
        "id": "W7YFBNfElXS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split de los textos"
      ],
      "metadata": {
        "id": "SQ1UGk32S8er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Creamos el text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Tamaño del chunk\n",
        "    chunk_size=1000,\n",
        "    # Solapamiento entre chunks\n",
        "    chunk_overlap=250\n",
        "    )"
      ],
      "metadata": {
        "id": "2BHgywg4S_Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario para los splits\n",
        "textos_cortados = {}\n",
        "\n",
        "# Cortamos uno a uno los textos\n",
        "for nombre, archivo in textos.items():\n",
        "  textos_cortados[nombre] = text_splitter.split_text(archivo)"
      ],
      "metadata": {
        "id": "_mtZecsfTCXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------- CONTROL DE CHUNKS ----------------------------------------------\n",
        "for i, txt in enumerate(textos_cortados['Marco_Legal_Educacion_Argentina']):\n",
        "  # Imprimimos la longitud de la cadena, y luego el trozo de texto (chunk)\n",
        "  print(f'Split: {i}/{len(textos_cortados[\"Marco_Legal_Educacion_Argentina\"])}')\n",
        "  print(f'Len: {len(txt)}\\nTexto:\\n{txt}')\n",
        "  print('')\n",
        "  # --------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "_o0afmNvTcmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding del texto y almacenamiento en ChromaDB:"
      ],
      "metadata": {
        "id": "zKt2reVfyxxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "# Creamos el objeto de la base de datos\n",
        "bd_chroma = chromadb.Client()"
      ],
      "metadata": {
        "id": "W5NcMyrZU8Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------- ELIMINAR COLECCIONES --------------------------------------\n",
        "# Eliminar una coleccion\n",
        "# bd_chroma.delete_collection(name=f\"Estatuto_Docente_BsAs\")\n",
        "\n",
        "# Eliminar todas las colecciones\n",
        "# for nombre in textos_cortados.keys():\n",
        "#   coleccion = bd_chroma.delete_collection(name=f\"{nombre}\")\n",
        "# ---------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "LriW1rimVSuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import tensorflow_text\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "\n",
        "# Se utiliza universal sentence encoder multilenguaje como embedding\n",
        "# es necesario modificar la función de embedding de ChromaDB (utilizada mas adelante a la hora de hacer get_collection)\n",
        "class MyEmbeddingFunction(EmbeddingFunction):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Variable de instancia\n",
        "        self.embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/multilingual/versions/2\")\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        embeddings = self.embed(input)\n",
        "        return embeddings\n",
        "\n",
        "funcion_embedding = MyEmbeddingFunction()"
      ],
      "metadata": {
        "id": "fg2pR55eVXDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario para los embeddings que generemos\n",
        "embeddings_textos_cortados = {}\n",
        "\n",
        "# Por cada archivo con split ya hecho\n",
        "for nombre, archivo in textos_cortados.items():\n",
        "    # Creamos los embeddings del documento\n",
        "    embeddings_textos_cortados[nombre] = funcion_embedding(textos_cortados[nombre]).numpy().tolist()\n",
        "    # Creamos una coleccion perteneciente a ese archivo\n",
        "    coleccion = bd_chroma.create_collection(name=f\"{nombre}\", metadata={\"hnsw:space\": \"cosine\"})\n",
        "    # Agregamos:\n",
        "    coleccion.add(\n",
        "        embeddings=embeddings_textos_cortados[nombre],\n",
        "        # Los splits\n",
        "        documents=archivo,\n",
        "        # Como metadata a que archivo pertenece dicho split\n",
        "        metadatas = [ {'Archivo': nombre} for _ in range(len(archivo)) ],\n",
        "        # Como id que número de chunk es dicho split\n",
        "        ids=[f'Número de chunk {str(x)}' for x in range(len(archivo))]\n",
        "    )"
      ],
      "metadata": {
        "id": "wHQWC8ZfVxkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Búsqueda Semántica"
      ],
      "metadata": {
        "id": "-AYXJ0C_owJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para realizar la busqueda semántica, recibe el string correspondiente al nombre de la colección (nombre del archivo) y la query\n",
        "def busqueda_semantica(archivo, query):\n",
        "    \"\"\"\n",
        "    Realiza una búsqueda semántica en la colección correspondiente al archivo utilizando una query.\n",
        "\n",
        "    Parámetros:\n",
        "    - archivo (str): Nombre del archivo (nombre de la colección) en la que se realizará la búsqueda.\n",
        "    - query (str): Query semántica a utilizar en la búsqueda.\n",
        "\n",
        "    Retorno:\n",
        "    - str: Resultado formateado en un string que incluye información sobre la similitud coseno, el documento más cercano y su id.\n",
        "    \"\"\"\n",
        "\n",
        "    # Cantidad de resultados que traera\n",
        "    cantidad_resultados=3\n",
        "    # A partir del nombre del archivo se obtiene la colección correspondiente\n",
        "    coleccion = bd_chroma.get_collection(name=archivo, embedding_function=funcion_embedding)\n",
        "    # Búsqueda\n",
        "    resultado_query = coleccion.query(\n",
        "        query_texts=query,\n",
        "        n_results=cantidad_resultados,\n",
        "        # where={\"Archivo\": {\"$eq\": 'Estatuto_Docente_BsAs'}},\n",
        "        # where_document={\"$contains\":\"director\"},\n",
        "        # Devuelve distancia (coseno seteada arriba), metadata (nombre del archivo) y los documentos mas cercanos (chunks correspondientes)\n",
        "        include=['distances', 'metadatas', 'documents']\n",
        "    )\n",
        "    # Formateo de los resultados para luego pasar al contexto del LLM.\n",
        "    resultado_limpio=f'Archivo: {archivo}\\n\\n'\n",
        "    for i in range(cantidad_resultados):\n",
        "      resultado_limpio += f'{resultado_query[\"ids\"][0][i]}:\\n'\n",
        "      resultado_limpio += f'Similitud coseno: {resultado_query[\"distances\"][0][i]}\\n'\n",
        "      resultado_limpio += f'{resultado_query[\"documents\"][0][i]}:\\n\\n'\n",
        "\n",
        "    # Devuelve el resultado formateado en un string\n",
        "    return resultado_limpio"
      ],
      "metadata": {
        "id": "X7vXtIVTWPpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------- CONTROL DE CONSULTA VECTORIAL ------------------------------------------------------\n",
        "print('Control de Consulta Vectorial:')\n",
        "print('')\n",
        "pregunta = '¿Cúantos días le corresponde a una docente de licencia por maternidad?'\n",
        "print(f'Pregunta: {pregunta}')\n",
        "print('')\n",
        "print(busqueda_semantica('Estatuto_Docente_BsAs', pregunta))\n",
        "# -------------------------------- FIN CONTROL DE CONSULTA VECTORIAL -----------------------------------------------------"
      ],
      "metadata": {
        "id": "-ASD615vb3sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Base de datos tabular"
      ],
      "metadata": {
        "id": "vuyDja-cy1I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lectura del xls"
      ],
      "metadata": {
        "id": "-P88vExifjFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta y nombre del archivo xls\n",
        "drive_path = \"/content/drive/MyDrive/UNR/4 - Proc Lenguaje Natural (IA42)/TP2/EduArDo/Data\"\n",
        "xls_file = \"Padron_Oficial_Establecimientos_Educativos.xls\""
      ],
      "metadata": {
        "id": "VD8Mh7Nv-9eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta completa del archivo xls\n",
        "xls_path = f\"{drive_path}/{xls_file}\"\n",
        "\n",
        "# Lee el archivo xls a partir de la fila 12 como cabecera\n",
        "padron_completo = pd.read_excel(xls_path, header=11)"
      ],
      "metadata": {
        "id": "wWFQtD4WhX06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padron_completo"
      ],
      "metadata": {
        "id": "njgRYriUkMVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padron_completo.info()"
      ],
      "metadata": {
        "id": "fxwbhB7Ji9kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filas_duplicadas = padron_completo.duplicated()\n",
        "print(\"Hay filas duplicadas.\") if filas_duplicadas.any() else print(\"No hay filas duplicadas.\")"
      ],
      "metadata": {
        "id": "r0uWJkTxj-XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padrón filtrado"
      ],
      "metadata": {
        "id": "MtUPWQ0TlIhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia del padrón completo con los registros correspondientes distritos en particular\n",
        "distritos_a_conservar = ['Buenos Aires']\n",
        "padron = padron_completo[padron_completo['Jurisdicción'].isin(distritos_a_conservar)].copy()"
      ],
      "metadata": {
        "id": "FXiR3UiEk-GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padrón Completo sin filtrar\n",
        "# padron = padron_completo.copy()"
      ],
      "metadata": {
        "id": "fBO3nuFvn0Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padron.info()"
      ],
      "metadata": {
        "id": "7ZNffa7RmDiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función de consulta tabular:"
      ],
      "metadata": {
        "id": "BhC0G03Njmi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def busqueda_tabular(nombre_escuela):\n",
        "    \"\"\"\n",
        "    Busca una escuela por su nombre en el DataFrame \"padron\" y devuelve los datos correspondientes,\n",
        "    omitiendo las columnas con valores NaN.\n",
        "\n",
        "    Parámetros:\n",
        "    - nombre_escuela (str): Nombre de la escuela a buscar.\n",
        "\n",
        "    Retorno:\n",
        "    - dict: Diccionario que contiene las columnas y valores de la escuela encontrada (sin NaN).\n",
        "      Retorna None si la escuela no se encuentra.\n",
        "    \"\"\"\n",
        "    # Buscar la escuela por nombre\n",
        "    resultado_busqueda = padron[padron['Nombre'] == nombre_escuela]\n",
        "\n",
        "    # Verificar si se encontraron resultados\n",
        "    if not resultado_busqueda.empty:\n",
        "        # Obtener la primera fila encontrada (suponiendo que los nombres son únicos)\n",
        "        escuela_encontrada = resultado_busqueda.iloc[0]\n",
        "\n",
        "        # Filtrar las columnas con valores no NaN\n",
        "        escuela_valida = {indice: valor for indice, valor in escuela_encontrada.items() if pd.notna(valor)}\n",
        "        # escuela_valida = [f\"{indice}: {valor}\" for indice, valor in escuela_encontrada.items() if pd.notna(valor)]\n",
        "\n",
        "        return escuela_valida\n",
        "    else:\n",
        "        print(f\"No se encontró ninguna escuela con el nombre '{nombre_escuela}'.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "LilYffJ5seCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------- CONTROL DE CONSULTA TABULAR ------------------------------------------------------\n",
        "print('Control de Consulta Tabular:')\n",
        "print('')\n",
        "escuela_buscar = 'INSTITUTO COMERCIAL RANCAGUA'\n",
        "resultado = busqueda_tabular(escuela_buscar)\n",
        "resultado\n",
        "# ----------------------------- FIN DE CONTROL DE CONSULTA VECTORIAL --------------------------------------------------"
      ],
      "metadata": {
        "id": "6ZVGfhehm__p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Base de datos de grafos:"
      ],
      "metadata": {
        "id": "tuj0eSPFt_yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creacion de las querys"
      ],
      "metadata": {
        "id": "_-r-35uAuC7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------------\n",
        "# INICIO SARMIENTO\n",
        "# ------------------------------------------------------------------------------------\n",
        "query_sarmiento = '''\n",
        "\n",
        "SELECT\n",
        "\n",
        "  ?nombreCompleto ?nacionalidad ?genero ?lealtad ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento\n",
        "  ?lugarFallecimiento ?circunstanciasMuerte ?causaMuerte ?lugarSepultura ?madre\n",
        "  (GROUP_CONCAT(DISTINCT ?_hermanos; SEPARATOR=\", \") AS ?hermanos)\n",
        "  ?conyuge ?hija\n",
        "  (GROUP_CONCAT(DISTINCT ?_ocupaciones; SEPARATOR=\", \") AS ?ocupaciones)\n",
        "  (GROUP_CONCAT(DISTINCT ?_cargosOcupados; SEPARATOR=\", \") AS ?cargosOcupados)\n",
        "  ?inicioPeriodoActividad ?partidoPolitico ?candidatoEleccionAño ?rangoMilitarAlcanzado\n",
        "  ?ramaMilitar\n",
        "  (GROUP_CONCAT(DISTINCT ?_obrasDestacadas; SEPARATOR=\", \") AS ?obrasDestacadas)\n",
        "\n",
        "WHERE\n",
        "\n",
        "{\n",
        "\n",
        "  wd:Q254041 wdt:P1559 ?nombreCompleto;\n",
        "             wdt:P27 [rdfs:label ?nacionalidad];\n",
        "             wdt:P21 [rdfs:label ?genero];\n",
        "             wdt:P945 [rdfs:label ?lealtad];\n",
        "             wdt:P569 ?fechaNacimiento;\n",
        "             wdt:P19 [rdfs:label ?lugarNacimiento];\n",
        "             wdt:P570 ?fechaFallecimiento;\n",
        "             wdt:P20 [rdfs:label ?lugarFallecimiento];\n",
        "             wdt:P1196 [rdfs:label ?circunstanciasMuerte];\n",
        "             wdt:P509 [rdfs:label ?causaMuerte];\n",
        "             wdt:P119 [rdfs:label ?lugarSepultura];\n",
        "             wdt:P25 [rdfs:label ?madre];\n",
        "             wdt:P3373 ?hermanos;\n",
        "             wdt:P26 [rdfs:label ?conyuge];\n",
        "             wdt:P40 [rdfs:label ?hija];\n",
        "             wdt:P106 ?ocupaciones;\n",
        "             wdt:P39 ?cargosOcupados;\n",
        "             wdt:P2031 ?inicioPeriodoActividad;\n",
        "             wdt:P102 [rdfs:label ?partidoPolitico];\n",
        "             wdt:P3602 [rdfs:label ?candidatoEleccionAño];\n",
        "             wdt:P410 [rdfs:label ?rangoMilitarAlcanzado];\n",
        "             wdt:P241 [rdfs:label ?ramaMilitar];\n",
        "             wdt:P800 ?obrasDestacadas;\n",
        "\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],es\".\n",
        "                          ?hermanos rdfs:label ?_hermanos.\n",
        "                          ?ocupaciones rdfs:label ?_ocupaciones.\n",
        "                          ?cargosOcupados rdfs:label ?_cargosOcupados.\n",
        "                          ?obrasDestacadas rdfs:label ?_obrasDestacadas.\n",
        "                         }\n",
        "\n",
        "  FILTER(LANG(?nacionalidad) = \"es\").\n",
        "  FILTER(LANG(?genero) = \"es\").\n",
        "  FILTER(LANG(?lealtad) = \"es\").\n",
        "  FILTER(LANG(?lugarNacimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarFallecimiento) = \"es\").\n",
        "  FILTER(LANG(?circunstanciasMuerte) = \"es\").\n",
        "  FILTER(LANG(?causaMuerte) = \"es\").\n",
        "  FILTER(LANG(?lugarSepultura) = \"es\").\n",
        "  FILTER(LANG(?madre) = \"es\").\n",
        "  FILTER(LANG(?conyuge) = \"es\").\n",
        "  FILTER(LANG(?hija) = \"es\").\n",
        "  FILTER(LANG(?partidoPolitico) = \"es\").\n",
        "  FILTER(LANG(?candidatoEleccionAño) = \"es\").\n",
        "  FILTER(LANG(?rangoMilitarAlcanzado) = \"es\").\n",
        "  FILTER(LANG(?ramaMilitar) = \"es\").\n",
        "\n",
        "}\n",
        "\n",
        "GROUP BY ?nombreCompleto ?nacionalidad ?genero ?lealtad ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento\n",
        "         ?lugarFallecimiento ?circunstanciasMuerte ?causaMuerte ?lugarSepultura ?madre ?conyuge ?hija ?inicioPeriodoActividad\n",
        "         ?partidoPolitico ?candidatoEleccionAño ?rangoMilitarAlcanzado ?ramaMilitar\n",
        "'''\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# FIN SARMIENTO\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# INICIO PELLEGRINI\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "query_pellegrini = '''\n",
        "\n",
        "SELECT\n",
        "\n",
        "   ?nombreCompleto ?genero\n",
        "  (GROUP_CONCAT(DISTINCT ?_nacionalidades; SEPARATOR=\", \") AS ?nacionalidades)\n",
        "  ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento\n",
        "  ?lugarSepultura\n",
        "  (GROUP_CONCAT(DISTINCT ?_ocupaciones; SEPARATOR=\", \") AS ?ocupaciones)\n",
        "  (GROUP_CONCAT(DISTINCT ?_cargosOcupados; SEPARATOR=\", \") AS ?cargosOcupados)\n",
        "  (GROUP_CONCAT(DISTINCT ?_educadoEn; SEPARATOR=\", \") AS ?educadoEn)\n",
        "  ?lugarTrabajo ?partidoPolitico ?ramaMilitar\n",
        "\n",
        "WHERE\n",
        "\n",
        "{\n",
        "  wd:Q270446 wdt:P21 [rdfs:label ?genero];\n",
        "             wdt:P27 ?nacionalidades;\n",
        "             wdt:P1559 ?nombreCompleto;\n",
        "             wdt:P569 ?fechaNacimiento;\n",
        "             wdt:P19 [rdfs:label ?lugarNacimiento];\n",
        "             wdt:P570 ?fechaFallecimiento;\n",
        "             wdt:P20 [rdfs:label ?lugarFallecimiento];\n",
        "             wdt:P119 [rdfs:label ?lugarSepultura];\n",
        "             wdt:P106 ?ocupaciones;\n",
        "             wdt:P39 ?cargosOcupados;\n",
        "             wdt:P69 ?educadoEn;\n",
        "             wdt:P937 [rdfs:label ?lugarTrabajo];\n",
        "             wdt:P102 [rdfs:label ?partidoPolitico];\n",
        "             wdt:P241 [rdfs:label ?ramaMilitar];\n",
        "\n",
        "\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],es\".\n",
        "                          ?nacionalidades rdfs:label ?_nacionalidades.\n",
        "                          ?ocupaciones rdfs:label ?_ocupaciones.\n",
        "                          ?cargosOcupados rdfs:label ?_cargosOcupados.\n",
        "                          ?educadoEn rdfs:label ?_educadoEn.\n",
        "                         }\n",
        "\n",
        "  FILTER(LANG(?genero) = \"es\").\n",
        "  FILTER(LANG(?lugarNacimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarFallecimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarSepultura) = \"es\").\n",
        "  FILTER(LANG(?lugarTrabajo) = \"es\").\n",
        "  FILTER(LANG(?partidoPolitico) = \"es\").\n",
        "  FILTER(LANG(?ramaMilitar) = \"es\").\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "GROUP BY ?nombreCompleto ?genero ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento ?lugarSepultura\n",
        "         ?lugarTrabajo ?partidoPolitico ?ramaMilitar\n",
        "\n",
        "'''\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# FIN PELLEGRINI\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# INICIO ROCA\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "query_roca = '''\n",
        "\n",
        "SELECT\n",
        "\n",
        "   ?nombreCompleto ?genero ?nacionalidad ?lealtad ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento\n",
        "   ?lugarSepultura ?padre ?madre ?hermana ?conyuge ?hijo\n",
        "  (GROUP_CONCAT(DISTINCT ?_ocupaciones; SEPARATOR=\", \") AS ?ocupaciones)\n",
        "  (GROUP_CONCAT(DISTINCT ?_cargos; SEPARATOR=\", \") AS ?cargos)\n",
        "   ?educadoEn ?partidoPolitico\n",
        "  (GROUP_CONCAT(DISTINCT ?_candidatoEnElecciones; SEPARATOR=\", \") AS ?candidatoEnElecciones)\n",
        "   ?religion ?rangoMilitarAlcanzado ?ramaMilitar\n",
        "\n",
        "WHERE\n",
        "\n",
        "{\n",
        "\n",
        "  wd:Q356659 wdt:P1559 ?nombreCompleto;\n",
        "             wdt:P21 [rdfs:label ?genero];\n",
        "             wdt:P27 [rdfs:label ?nacionalidad];\n",
        "             wdt:P945 [rdfs:label ?lealtad];\n",
        "             wdt:P569 ?fechaNacimiento;\n",
        "             wdt:P19 [rdfs:label ?lugarNacimiento];\n",
        "             wdt:P570 ?fechaFallecimiento;\n",
        "             wdt:P20 [rdfs:label ?lugarFallecimiento];\n",
        "             wdt:P119 [rdfs:label ?lugarSepultura];\n",
        "             wdt:P22 [rdfs:label ?padre];\n",
        "             wdt:P25 [rdfs:label ?madre];\n",
        "             wdt:P3373 [rdfs:label ?hermana];\n",
        "             wdt:P26 [rdfs:label ?conyuge];\n",
        "             wdt:P40 [rdfs:label ?hijo];\n",
        "             wdt:P106 ?ocupaciones;\n",
        "             wdt:P39 ?cargos;\n",
        "             wdt:P69 [rdfs:label ?educadoEn];\n",
        "             wdt:P102 [rdfs:label ?partidoPolitico];\n",
        "             wdt:P3602 ?candidatoEnElecciones;\n",
        "             wdt:P140 [rdfs:label ?religion];\n",
        "             wdt:P410 [rdfs:label ?rangoMilitarAlcanzado];\n",
        "             wdt:P241 [rdfs:label ?ramaMilitar];\n",
        "\n",
        "\n",
        "\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],es\".\n",
        "                          ?ocupaciones rdfs:label ?_ocupaciones.\n",
        "                          ?cargos rdfs:label ?_cargos.\n",
        "                          ?candidatoEnElecciones rdfs:label ?_candidatoEnElecciones.\n",
        "\n",
        "                         }\n",
        "\n",
        "  FILTER(LANG(?genero) = \"es\").\n",
        "  FILTER(LANG(?nacionalidad) = \"es\").\n",
        "  FILTER(LANG(?lealtad) = \"es\").\n",
        "  FILTER(LANG(?lugarNacimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarFallecimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarSepultura) = \"es\").\n",
        "  FILTER(LANG(?padre) = \"es\").\n",
        "  FILTER(LANG(?madre) = \"es\").\n",
        "  FILTER(LANG(?hermana) = \"es\").\n",
        "  FILTER(LANG(?conyuge) = \"es\").\n",
        "  FILTER(LANG(?hijo) = \"es\").\n",
        "  FILTER(LANG(?educadoEn) = \"es\").\n",
        "  FILTER(LANG(?partidoPolitico) = \"es\").\n",
        "  FILTER(LANG(?religion) = \"es\").\n",
        "  FILTER(LANG(?rangoMilitarAlcanzado) = \"es\").\n",
        "  FILTER(LANG(?ramaMilitar) = \"es\").\n",
        "\n",
        "}\n",
        "\n",
        "GROUP BY ?nombreCompleto ?genero ?nacionalidad ?lealtad ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento\n",
        "         ?lugarSepultura ?padre ?madre ?hermana ?conyuge ?hijo ?educadoEn ?partidoPolitico ?religion ?rangoMilitarAlcanzado\n",
        "         ?ramaMilitar\n",
        "\n",
        "'''\n",
        "# ------------------------------------------------------------------------------------\n",
        "# FIN ROCA\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# INICIO JAURETCHE\n",
        "# ------------------------------------------------------------------------------------\n",
        "\n",
        "query_jauretche = '''\n",
        "\n",
        "SELECT\n",
        "\n",
        "   ?nombreCompleto ?genero ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento ?causaMuerte\n",
        "  (GROUP_CONCAT(DISTINCT ?_ocupaciones; SEPARATOR=\", \") AS ?ocupaciones)\n",
        "   ?campoTrabajo ?educadoEn\n",
        "\n",
        "WHERE\n",
        "\n",
        "{\n",
        "\n",
        "   wd:Q715315 rdfs:label ?nombreCompleto;\n",
        "              wdt:P21 [rdfs:label ?genero];\n",
        "              wdt:P27 [rdfs:label ?nacionalidad];\n",
        "              wdt:P569 ?fechaNacimiento;\n",
        "              wdt:P19 [rdfs:label ?lugarNacimiento];\n",
        "              wdt:P570 ?fechaFallecimiento;\n",
        "              wdt:P20 [rdfs:label ?lugarFallecimiento];\n",
        "              wdt:P509 [rdfs:label ?causaMuerte];\n",
        "              wdt:P106 ?ocupaciones;\n",
        "              wdt:P101 [rdfs:label ?campoTrabajo];\n",
        "              wdt:P69 [rdfs:label ?educadoEn];\n",
        "\n",
        "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],es\".\n",
        "                          ?ocupaciones rdfs:label ?_ocupaciones.\n",
        "\n",
        "                         }\n",
        "\n",
        "  FILTER(LANG(?nombreCompleto) = \"es\").\n",
        "  FILTER(LANG(?genero) = \"es\").\n",
        "  FILTER(LANG(?nacionalidad) = \"es\").\n",
        "  FILTER(LANG(?lugarNacimiento) = \"es\").\n",
        "  FILTER(LANG(?lugarFallecimiento) = \"es\").\n",
        "  FILTER(LANG(?causaMuerte) = \"es\").\n",
        "  FILTER(LANG(?campoTrabajo) = \"es\").\n",
        "  FILTER(LANG(?educadoEn) = \"es\").\n",
        "\n",
        "}\n",
        "\n",
        " GROUP BY ?nombreCompleto ?genero ?fechaNacimiento ?lugarNacimiento ?fechaFallecimiento ?lugarFallecimiento ?causaMuerte ?campoTrabajo\n",
        "          ?educadoEn\n",
        "\n",
        "'''\n",
        "# ------------------------------------------------------------------------------------\n",
        "# FIN JAURETCHE\n",
        "# ------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ugAqcWfeoMwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Función para hacer la consulta:"
      ],
      "metadata": {
        "id": "6aPU1X_5uPPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def consulta_sparql(query):\n",
        "    \"\"\"\n",
        "    Realiza una consulta SPARQL a Wikidata y devuelve los resultados formateados en un string.\n",
        "\n",
        "    Parámetros:\n",
        "    - query (str): Consulta SPARQL a ejecutar en Wikidata.\n",
        "\n",
        "    Retorno:\n",
        "    - str: String que contiene los resultados formateados de la consulta SPARQL.\n",
        "      Retorna None si hay un error durante la consulta.\n",
        "    \"\"\"\n",
        "\n",
        "    # URL donde se enviara la consulta\n",
        "    url = \"https://query.wikidata.org/sparql\"\n",
        "\n",
        "    # Configuración de la consulta SPARQL\n",
        "    headers = {\n",
        "        # Valor generalmente asociado a navegador web Chrome. Indica al servidor que la solicitud proviene de un navegador (aunque sea un script)\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "        # Queremos recibir un json\n",
        "        'Accept': 'application/json'\n",
        "    }\n",
        "\n",
        "    params = {\n",
        "        # Consulta SPARQL a consultar\n",
        "        'query': query,\n",
        "        # Recibimos un json.\n",
        "        'format': 'json'\n",
        "    }\n",
        "\n",
        "    # Realización de la solicitud GET.\n",
        "    response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "    # Si la respuesta fue exitosa\n",
        "    if response.status_code == 200:\n",
        "\n",
        "        # Verificamos el json\n",
        "        if response.json():\n",
        "\n",
        "            # Creamos el string para el contexto con los resultados\n",
        "            resultado = response.json()['results']['bindings'][0]\n",
        "            respuesta_wikidata = ''\n",
        "            for key in resultado.keys():\n",
        "                respuesta_wikidata += f'{key}: {resultado[key][\"value\"]}\\n'\n",
        "\n",
        "        return respuesta_wikidata\n",
        "\n",
        "    # Sino\n",
        "    else:\n",
        "        print(\"Error al realizar la consulta. Código de estado:\", response.status_code)\n",
        "        # Devolvemos nulo\n",
        "        return None"
      ],
      "metadata": {
        "id": "eJL3QQmIuRj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ---------------------------------- CONTROL DE CONSULTA DE GRAFOS ------------------------------------------------------\n",
        "# print('Control de Consulta de Grafos:')\n",
        "# print('')\n",
        "# print(consulta_sparql(query_sarmiento))\n",
        "# # ------------------------------- FIN DE CONTROL DE CONSULTA DE GRAFOS --------------------------------------------------"
      ],
      "metadata": {
        "id": "ijRSbh8CuVcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Funcionamiento del Chabot:"
      ],
      "metadata": {
        "id": "WJAqXXxzuZBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jinja2 import Template\n",
        "from decouple import config\n",
        "from ast import Str\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "W6FEkf8auYMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clasificador"
      ],
      "metadata": {
        "id": "5DzGD2yjvB4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clasificador zero-shot de HugginFace\n",
        "# Utilizado como segunda etapa del Clasificador de categorias y clasificador de archivos\n",
        "clasificador_zero_shot = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
        "\n",
        "# Se utilizan dos listas de etiquetas distintas porque en un caso el clasificador busca textos,\n",
        "# y en el otro caso lo que busca es información de personalidades.\n",
        "\n",
        "# Dos grupos de etiquetas para el clasificador\n",
        "etiquetas_textos = ['Marco Legal',\n",
        "            'Ley Educación Nacional 26206',\n",
        "            'Reglamento General',\n",
        "            'Estatuto Docente']\n",
        "\n",
        "etiquetas_personas = ['Domingo Faustino Sarmiento',\n",
        "                    'Carlos Pellegrini', 'Julio Argentino Roca',\n",
        "                    'Arturo Jauretche']\n",
        "\n",
        "# Etiquetas para la segunda etapa del clasificador de categorias\n",
        "etiquetas_base_datos = ['1', '2', '3', '4']"
      ],
      "metadata": {
        "id": "p3ONUA60ufHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plantilla Jinja"
      ],
      "metadata": {
        "id": "40aHfTfDu71o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función que define la plantilla jinja\n",
        "def plantilla_instruccion_zephyr(messages, add_generation_prompt=True):\n",
        "  template_str = \"{% for message in messages %}\"\n",
        "  template_str += \"{% if message['role'] == 'user' %}\"\n",
        "  template_str += \"<|user|>{{ message['content'] }}</s>\\n\"\n",
        "  template_str += \"{% elif message['role'] == 'assistant' %}\"\n",
        "  template_str += \"<|assistant|>{{ message['content'] }}</s>\\n\"\n",
        "  template_str += \"{% elif message['role'] == 'system' %}\"\n",
        "  template_str += \"<|system|>{{ message['content'] }}</s>\\n\"\n",
        "  template_str += \"{% else %}\"\n",
        "  template_str += \"<|unknown|>{{ message['content'] }}</s>\\n\"\n",
        "  template_str += \"{% endif %}\"\n",
        "  template_str += \"{% endfor %}\"\n",
        "  template_str += \"{% if add_generation_prompt %}\"\n",
        "  template_str += \"<|assistant|>\\n\"\n",
        "  template_str += \"{% endif %}\"\n",
        "  # Crear un objeto de plantilla con la cadena de plantilla\n",
        "  template = Template(template_str)\n",
        "  # Renderizar la plantilla con los mensajes proporcionados\n",
        "  return template.render(messages=messages, add_generation_prompt=add_generation_prompt)\n"
      ],
      "metadata": {
        "id": "jC0jle3XwC_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo LLM"
      ],
      "metadata": {
        "id": "DYLIkPn_0_Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Llamada al modelo\n",
        "def conexion_llm(prompt: str, max_new_tokens: int = 768) -> None:\n",
        "  try:\n",
        "    # Tu clave API de Hugging Face\n",
        "    api_key = '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'\n",
        "\n",
        "    # URL de la API de Hugging Face para la generación de texto\n",
        "    api_url = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "    # Cabeceras para la solicitud\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
        "\n",
        "    # Datos para enviar en la solicitud POST\n",
        "    # Sobre los parámetros: https://huggingface.co/docs/transformers/main_classes/text_generation\n",
        "    data = {\n",
        "      \"inputs\": prompt,\n",
        "      \"parameters\": {\n",
        "        \"max_new_tokens\": max_new_tokens,\n",
        "        \"temperature\": 0.01,\n",
        "      }\n",
        "    }\n",
        "\n",
        "    # Realizamos la solicitud POST\n",
        "    response = requests.post(api_url, headers=headers, json=data)\n",
        "\n",
        "    # Extraer respuesta\n",
        "    respuesta = response.json()[0][\"generated_text\"][len(prompt):]\n",
        "\n",
        "    return respuesta\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error durante la conexion con el LLM: Error {e}\")"
      ],
      "metadata": {
        "id": "jjwMkkVA1E1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt engineering"
      ],
      "metadata": {
        "id": "iZtS54pJ1Zu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clasificador de Bases de Datos\n",
        "\n",
        "# Primera etapa del clasificador de categorias:\n",
        "def clasificador_base_datos(prompt_inicial: str):\n",
        "\n",
        "  PLANTILLA_CLASIFICACION_BASE_DATOS = (\n",
        "    \"Clasifica el texto recibido en, estrictamente, una de las categorías mencionadas a continuación.\\n\"\n",
        "    \"Categorias:\\n\"\n",
        "     \"1\\n\"\n",
        "     \"2\\n\"\n",
        "     \"3\\n\"\n",
        "     \"4\\n\"\n",
        "     '''La categoria 1 corresponde al marco legal de la educación argentina y en particular de la provincia de Buenos Aires.\n",
        "     Corresponde a leyes, normas y regulaciones que afecten a las instituciones educativas o a cualquiera de los agentes\n",
        "     y personas que participan en ellas.\n",
        "     Por ejemplo: artículos de la Ley de Educación Nacional, del Reglamento General de Escuelas de Buenos Aires, del Estatuto Docente, etc.\\n'''\n",
        "     '''La categoria 2 corresponde a datos generales sobre los personajes más influyentes en la historia educativa argentina.\n",
        "     Por ejemplo: datos sobre Domingo Faustino Sarmiento, Carlos Pellegrini, Julio Argentino Roca y Arturo Jauretche.\\n'''\n",
        "     '''La categoria 3 corresponde a datos específicos de todas las instituciones educativas del país.\n",
        "     Por ejemplo: nombre, CUE, jurisdicción, sector público o privado, domicilio, localidad, teléfono, mail, etc.\\n'''\n",
        "     '''La categoria 4 corresponde a consultas que no estén relacionadas con ninguna de las anteriores.\\n\"'''\n",
        "     \"Pregunta: {prompt_inicial}\\n\"\n",
        "     \"Respuesta: \"\n",
        "  )\n",
        "\n",
        "  mensaje = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": '''Eres un experto clasificador de textos en categorias.''',\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": PLANTILLA_CLASIFICACION_BASE_DATOS.format(prompt_inicial=prompt_inicial)},\n",
        "  ]\n",
        "\n",
        "  prompt_plantilla = plantilla_instruccion_zephyr(mensaje)\n",
        "\n",
        "  clasificacion_base_datos = conexion_llm(prompt_plantilla)\n",
        "\n",
        "  return clasificacion_base_datos\n"
      ],
      "metadata": {
        "id": "BAslh7fg3jWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limpiar Prompt de Textos\n",
        "\n",
        "# Función que utiliza el LLM para limpiar el prompt de consulta a la base de datos semántica:\n",
        "def limpiar_prompt_texto(prompt_inicial: str):\n",
        "\n",
        "  PLANTILLA_LIMPIAR_PROMPT_TEXTO = (\n",
        "     \"Cadena de texto: {prompt_inicial}.\\n\"\n",
        "  )\n",
        "\n",
        "  mensaje = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": '''Eres un asistente especialista en sintaxis que recibe una cadena de texto ingresada por el usuario.\n",
        "      El prompt ingresado tratará acerca de algún documento sobre la normativa y el marco legal de la Educación Argentina\n",
        "      Tu tarea es devolver la misma cadena pero quitándole el nombre del documento en cuestión.\\n\n",
        "      Los documentos a los que se puede hacer referencia son \"Marco Legal de la Educación Argentina\",\n",
        "      \"Ley de Educación Nacional 26206\", \"Reglamento General de Escuelas de Buenos Aires\" y\n",
        "      \"Estatuto Docente de Buenos Aires\".\\n'''\n",
        "      \"------------------------------------------------------------------------\\n\"\n",
        "      '''Ejemplo 1:\\n\n",
        "      Cadena de texto: ¿Cuánto tiempo es la licencia por matrimonio según el Estatuto Docente?\\n\n",
        "      Cadena de texto sin el nombre del documento: ¿Cuánto tiempo es la licencia por matrimonio?\\n'''\n",
        "      '''Ejemplo 2:\\n\n",
        "      Cadena de texto: ¿Según la Ley de Educación Nacional, un docente tiene derecho a capacitación?\\n\n",
        "      Cadena de texto sin el nombre del documento: ¿Un docente tiene derecho a capacitación?\\n'''\n",
        "      '''Ejemplo 3:\\n\n",
        "      Cadena de texto: ¿Según el Reglamento General de Escuelas, quién debe reemplazar al director en caso de ausencia?\\n\n",
        "      Cadena de texto sin el nombre del documento: ¿quién debe reemplazar al director en caso de ausencia?\\n'''\n",
        "      \"------------------------------------------------------------------------\\n\"\n",
        "      '''Tu salida debe ser únicamente el texto formateado.\\n''',\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": PLANTILLA_LIMPIAR_PROMPT_TEXTO.format(prompt_inicial=prompt_inicial)},\n",
        "  ]\n",
        "\n",
        "  prompt_plantilla = plantilla_instruccion_zephyr(mensaje)\n",
        "\n",
        "  prompt_limpio_llm = conexion_llm(prompt_plantilla)\n",
        "\n",
        "  # Últimos retoques que dejan el prompt limpio\n",
        "  prompt_limpio = prompt_limpio_llm.split('Cadena de texto sin el nombre del documento: ')[1].split('\\n')[0]\n",
        "\n",
        "  return prompt_limpio"
      ],
      "metadata": {
        "id": "MNzzv7Eo3nMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limpiar Prompt a MAYUS\n",
        "\n",
        "# Función que utiliza el LLM para limpiar el prompt de consulta a la base de datos tabular:\n",
        "def limpiar_prompt_mayus(prompt_inicial: str):\n",
        "\n",
        "  PLANTILLA_LIMPIAR_PROMPT_MAYUS = (\n",
        "     \"Cadena de texto: {prompt_inicial}.\\n\"\n",
        "  )\n",
        "\n",
        "  mensaje = [\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": '''Eres un asistente especialista en gramática que recibe una cadena de texto ingresada por el usuario.\n",
        "      El prompt ingresado tratará acerca de alguna institución educativa de Argentina.\n",
        "      Tu tarea es filtrar el prompt y devolver únicamente el nombre de la institución mencionado en el mismo, todo en mayúsculas, quitándole el resto del texto.\n",
        "      No deberás modificar el nombre de la institución ni agregar texto.\\n'''\n",
        "      \"------------------------------------------------------------------------\\n\"\n",
        "      \"Ejemplo 1:\\n\"\n",
        "      \"Cadena de texto: ¿Puedes darme los datos de contacto del 'Instituto Comercial Rancagua'?\\n\"\n",
        "      \"Cadena de texto de salida en mayúsculas: INSTITUTO COMERCIAL RANCAGUA\\n\"\n",
        "      \"Ejemplo 2:\\n\"\n",
        "      \"Cadena de texto: Necesito información sobre el 'Instituto Politecnico N° 6 General San Martin'\\n\"\n",
        "      \"Cadena de texto de salida en mayúsculas: INSTITUTO POLITECNICO N° 6 GENERAL SAN MARTIN\\n\"\n",
        "      \"Ejemplo 3:\\n\"\n",
        "      \"Cadena de texto: ¿Tienes datos de contacto del 'Colegio Nuestra Señora del Huerto'?\\n\"\n",
        "      \"Cadena de texto de salida en mayúsculas: COLEGIO NUESTRA SEÑORA DEL HUERTO\\n\"\n",
        "      \"------------------------------------------------------------------------\\n\"\n",
        "      '''Tu salida debe ser únicamente el texto formateado.\\n''',\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": PLANTILLA_LIMPIAR_PROMPT_MAYUS.format(prompt_inicial=prompt_inicial)},\n",
        "  ]\n",
        "\n",
        "  prompt_plantilla = plantilla_instruccion_zephyr(mensaje)\n",
        "\n",
        "  prompt_mayus_llm = conexion_llm(prompt_plantilla)\n",
        "\n",
        "  # Últimos retoques que dejan el prompt limpio\n",
        "  prompt_mayus = prompt_mayus_llm.split('Cadena de texto de salida en mayúsculas: ')[1].split('\\n')[0]\n",
        "\n",
        "  return prompt_mayus"
      ],
      "metadata": {
        "id": "aDk8v2jSTXwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Respuesta Final\n",
        "\n",
        "# Función para generar la respuesta final (compartida para todas las categorías)\n",
        "def generar_respuesta_final(query_str: str, contexto: str):\n",
        "\n",
        "  TEXT_QA_PROMPT_TMPL = (\n",
        "    \"\\n\\n------------------------------------------------------------------------\\n\"\n",
        "    \"Informacion de contexto:\\n\"\n",
        "    \"{context_str}\\n\"\n",
        "    \"------------------------------------------------------------------------\\n\"\n",
        "    \"Pregunta: {query_str}\\n\"\n",
        "    \"Respuesta: \\n\\n\"\n",
        "  )\n",
        "\n",
        "\n",
        "  messages = [\n",
        "    {\n",
        "\n",
        "    \"role\": \"system\",\n",
        "    \"content\": '''Responde en ESPAÑOL.\\n\n",
        "Eres un asistente especializado en educación argentina que responde amablemente preguntas guiándose únicamente por la\n",
        "informacion de contexto pero respondes como si esta no existiera y fueras tu quien lo sabía de antemano.\\n\n",
        "'''\n",
        "    \"Responde lo más corto posible.\\n\"\n",
        "    \"Responde sin utilizar conocimiento previo.\\n\"\n",
        "    '''Si la respuesta no esta en la informacion de contexto escribe la siguiente respuesta: 'Disculpa no puedo\n",
        "responder a la pregunta en este momento'.\\n'''\n",
        "\n",
        "    },\n",
        "\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": TEXT_QA_PROMPT_TMPL.format(context_str=contexto, query_str=query_str)},\n",
        "  ]\n",
        "\n",
        "  prompt_final = plantilla_instruccion_zephyr(messages)\n",
        "\n",
        "  # # --------------------------------------- CONTROL DE PROMPT QUE RECIBE EL LLM  -----------------------------------------------------------\n",
        "  # print('----------------------------------------------------------------------------------------')\n",
        "  # print('')\n",
        "  # print('Control Prompt que recibe el LLM:')\n",
        "  # print('')\n",
        "  # print(prompt_final)\n",
        "  # print('----------------------------------------------------------------------------------------')\n",
        "  # print('')\n",
        "  # # ------------------------------------- FIN CONTROL DE PROMPT QUE RECIBE EL LLM  ---------------------------------------------------------\n",
        "\n",
        "  respuesta_final = conexion_llm(prompt_final)\n",
        "\n",
        "  return respuesta_final"
      ],
      "metadata": {
        "id": "NKCM_UfL5tpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Respuesta ChatBot\n",
        "\n",
        "# Función que deriva la consulta a la base de datos correspondiente para buscar el contexto y luego genera la respuesta\n",
        "def respuesta_chatbot(nombre, pregunta: str, categoria: str):\n",
        "\n",
        "  if categoria == '1': resultado_bdd = busqueda_semantica(nombre, pregunta)\n",
        "  elif categoria == '2': resultado_bdd = consulta_sparql(nombre)\n",
        "  elif categoria == '3': resultado_bdd = busqueda_tabular(nombre)\n",
        "\n",
        "  respuesta = generar_respuesta_final(pregunta, resultado_bdd)\n",
        "\n",
        "  return respuesta\n"
      ],
      "metadata": {
        "id": "p6RiBcpDvABp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot"
      ],
      "metadata": {
        "id": "BsQKVG7_wqUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot():\n",
        "\n",
        "  while True:\n",
        "\n",
        "    print('---------------------------------------------- Nuevo mensaje ----------------------------------------------')\n",
        "    print('')\n",
        "\n",
        "    print('''Asistente: Hola, soy \"EduArDo\", un chatbot especializado en temas relacionados\n",
        "    al marco legal de la Educación Argentina. Si bien poseo información general de todo el país,\n",
        "    me especializo en particular en la provincia de Buenos Aires.\n",
        "    Puedo ayudarte con aspectos técnicos y normativos de leyes, reglamentos y estatutos.\n",
        "    También puedo brindar información detallada de los personajes más influyentes\n",
        "    en la historia educativa argentina (Sarmiento, Pellegrini, Roca, Jauretche),\n",
        "    así como también buscarte información de contacto de una institución educativa en particular.\n",
        "    En que puedo ayudarte? [Escribe \"salir\" para finalizar sesión]''')\n",
        "    print('')\n",
        "\n",
        "    pregunta = input('Usuario: ')\n",
        "    print('')\n",
        "\n",
        "    if (pregunta == 'salir'):\n",
        "      print('Asistente: Espero haber sido de utilidad. Hasta pronto! ')\n",
        "      break\n",
        "\n",
        "    # Clasificador creado con el mismo LLM para saber a que base de datos ir,\n",
        "    # elige un número dependiendo la base de datos que se necesite.\n",
        "    clasificacion_bdd_llm = clasificador_base_datos(pregunta)\n",
        "\n",
        "    # Como no se logró que el clasificador anterior devuelva solo un número para las categorias\n",
        "    # Se pasa el resultado anterior a otro clasificador (zero-shot sacado de HugginFace) para obtener la categoria.\n",
        "    clasificacion_bdd_zero = clasificador_zero_shot(clasificacion_bdd_llm, etiquetas_base_datos, multi_label=False)\n",
        "\n",
        "    # # ------------------------------------- CONTROL DE CLASIFICADOR DE CATEGORIAS  ---------------------------------------------------------\n",
        "    # # Descomentar para controlar como se eligieron las bases de datos\n",
        "    # print('--------------------------------------------------------------------------')\n",
        "    # print('')\n",
        "    # print('Control Clasificador de categorias de 2 etapas:')\n",
        "    # print('')\n",
        "    # print('Etapa 1: Clasificacion de LLM')\n",
        "    # print(clasificacion_bdd_llm)\n",
        "    # print('')\n",
        "    # print('Etapa 2: Clasificacion Zero-Shot')\n",
        "    # print(f'Etiquetas: {clasificacion_bdd_zero[\"labels\"]}')\n",
        "    # print(f'Puntajes: {clasificacion_bdd_zero[\"scores\"]}')\n",
        "    # print('')\n",
        "    # categorias = { '1': 'Marco legal', '2': 'Informacion de personalidades', '3': 'Datos de instituciones', '4': 'No corresponde a una categoria'}\n",
        "    # print(f'Categoria: {categorias[clasificacion_bdd_zero[\"labels\"][0]]}')\n",
        "    # print('')\n",
        "    # print('--------------------------------------------------------------------------')\n",
        "    # print('')\n",
        "    # # ---------------------------------- FIN DE CONTROL CLASIFICADOR DE CATEGORIAS --------------------------------------------------------\n",
        "\n",
        "    # Ahora si ya tenemos las categorias con probabilidades, si la mayor probabilidad es menor a determinado umbral\n",
        "    if (clasificacion_bdd_zero['scores'][0] < 0.65) or (clasificacion_bdd_zero['labels'][0] == '4'):\n",
        "\n",
        "      # No estamos seguros que se esté pidiendo un ainformación que el asistente conozca\n",
        "      print('''Asistente: Disculpa pero no estoy seguro de comprender qué tipo de información necesitas.\n",
        "      Recuerda que sólo puedo ayudarte con el marco legal de la educación argentina, personalidades destacadas y datos institucionales.\n",
        "      ¿Puedes reformular la pregunta?\\n''')\n",
        "\n",
        "    # Si las probabilidades superan umbral\n",
        "    else:\n",
        "\n",
        "      # CATEGORÍA = 1\n",
        "      # --> preguntas del marco legal / búsqueda semántica / base de datos vectorial:\n",
        "      if clasificacion_bdd_zero['labels'][0] == '1':\n",
        "\n",
        "        # Usamos nuevamente el clasificador zero-shot de HF para saber de que texto se trata la solicitud del usuario\n",
        "        clasificacion_zero_textos = clasificador_zero_shot(pregunta, etiquetas_textos, multi_label=False)\n",
        "\n",
        "        # # ------------------------------------- CONTROL DE CLASIFICADOR DE TEXTOS -------------------------------------------------------------\n",
        "        # # Descomentar para controlar como se eligio el texto que menciona el prompt\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # print('Control de Clasificador de Textos (Para BD vectorial):')\n",
        "        # print('')\n",
        "        # print(f'Etiquetas: {clasificacion_zero_textos[\"labels\"]}')\n",
        "        # print(f'Puntajes: {clasificacion_zero_textos[\"scores\"]}')\n",
        "        # print('')\n",
        "        # print(f'Texto: {clasificacion_zero_textos[\"labels\"][0]}')\n",
        "        # print('')\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # # --------------------------------- FIN DE CONTROL DE CLASIFICADOR DE TEXTOS -----------------------------------------------------------\n",
        "\n",
        "        # Si la etiqueta más probable es menor a umbral mínimo\n",
        "        if clasificacion_zero_textos['scores'][0] < 0.50:\n",
        "\n",
        "          # No entedemos bien a que texto se refiere\n",
        "          print('''Asistente: Disculpa pero no entiendo a qué tipo de documentación hace referencia tu consulta.\n",
        "          Recuerda que por el momento sólo poseo conocimientos en \"Marco Legal de la Educación Argentina\", \"Ley de Educación Nacional 26206\",\n",
        "          \"Reglamento General de Escuelas de Buenos Aires\" y \"Estatuto Docente de Buenos Aires\".\n",
        "          ¿Podrías reformular tu pregunta?\\n''')\n",
        "\n",
        "        # Si la etiqueta más probable supera ese umbral\n",
        "        else:\n",
        "\n",
        "          prompt_limpio = limpiar_prompt_texto(pregunta)\n",
        "\n",
        "          # # -------------------------------------- CONTROL DE LIMPIEZA DE PROMPT ----------------------------------------------------------\n",
        "          # print('--------------------------------------------------------------------------')\n",
        "          # print('Control de Limpieza de Prompt')\n",
        "          # print('')\n",
        "          # print('')\n",
        "          # print(f'Pregunta original: {pregunta}')\n",
        "          # print('')\n",
        "          # print(f'Pregunta limpia: {prompt_limpio}')\n",
        "          # print('')\n",
        "          # print('--------------------------------------------------------------------------')\n",
        "          # print('')\n",
        "          # # ------------------------------------ FIN CONTROL DE LIMPIEZA DE PROMPT --------------------------------------------------------\n",
        "\n",
        "          # Dependiendo el texto que nombre la etiqueta, buscamos en la base de datos vectorial y generamos la respuesta\n",
        "          if clasificacion_zero_textos['labels'][0] == 'Marco Legal': print(f'Asistente: {respuesta_chatbot(\"Marco_Legal_Educacion_Argentina\", prompt_limpio,\"1\")}')\n",
        "          elif clasificacion_zero_textos['labels'][0] == 'Ley Educación Nacional 26206': print(f'Asistente: {respuesta_chatbot(\"Ley_Educacion_Nacional_26206\", prompt_limpio,\"1\")}')\n",
        "          elif clasificacion_zero_textos['labels'][0] == 'Reglamento General': print(f'Asistente: {respuesta_chatbot(\"Reglamento_Gral_Escuelas_BsAs\", prompt_limpio,\"1\")}')\n",
        "          elif clasificacion_zero_textos['labels'][0] == 'Estatuto Docente': print(f'Asistente: {respuesta_chatbot(\"Estatuto_Docente_BsAs\", prompt_limpio,\"1\")}')\n",
        "\n",
        "\n",
        "\n",
        "      # CATEGORÍA = 2\n",
        "      # --> preguntas de información de personalidades / búsqueda sparql / base de datos grafos:\n",
        "      elif clasificacion_bdd_zero['labels'][0] == '2':\n",
        "\n",
        "        # Usamos nuevamente el clasificador zero-shot de HF para saber a qué personalidad refiere la pregunta\n",
        "        clasificacion_zero_pers = clasificador_zero_shot(pregunta, etiquetas_personas, multi_label=False)\n",
        "\n",
        "        # # ------------------------------------- Control de Clasificador de Personas -------------------------------------------------------------\n",
        "        # # Descomentar para controlar como se eligió la persona que menciona el prompt\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # print('Control Clasificador de Personalidades (Para BD de grafos)')\n",
        "        # print('')\n",
        "        # print(f'Etiquetas: {clasificacion_zero_pers[\"labels\"]}')\n",
        "        # print(f'Puntajes: {clasificacion_zero_pers[\"scores\"]}')\n",
        "        # print('')\n",
        "        # print(f'Personalidad: {clasificacion_zero_pers[\"labels\"][0]}')\n",
        "        # print('')\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # # ---------------------------------- Fin control de Clasificador de Personas ------------------------------------------------------------\n",
        "\n",
        "        # Si la etiqueta más probable es menor a umbral mínimo\n",
        "        if clasificacion_zero_pers['scores'][0] < 0.50:\n",
        "\n",
        "          # No entedemos bien a que persona se refiere\n",
        "          print('''Asistente: Disculpa pero no entiendo a quién hace referencia tu consulta.\n",
        "          Recuerda que por el momento sólo poseo conocimientos sobre \"Domingo Faustino Sarmiento\", \"Carlos Pellegrini\",\n",
        "          \"Julio Argentino Roca\" y \"Arturo Jauretche\".\n",
        "          ¿Podrías reformular tu pregunta?.''')\n",
        "\n",
        "        # Si la etiqueta más probable supera ese umbral\n",
        "        else:\n",
        "\n",
        "          # Dependiendo el apellido que nombre la etiqueta, buscamos en la base de datos de grafos\n",
        "          # con la query correspondiente generada arriba y generamos la respuesta\n",
        "          if clasificacion_zero_pers['labels'][0] == 'Domingo Faustino Sarmiento': print(f'Asistente: {respuesta_chatbot(query_sarmiento, pregunta, \"2\")}')\n",
        "          elif clasificacion_zero_pers['labels'][0] == 'Carlos Pellegrini': print(f'Asistente: {respuesta_chatbot(query_pellegrini, pregunta, \"2\")}')\n",
        "          elif clasificacion_zero_pers['labels'][0] == 'Julio Argentino Roca': print(f'Asistente: {respuesta_chatbot(query_roca, pregunta, \"2\")}')\n",
        "          elif clasificacion_zero_pers['labels'][0] == 'Arturo Jauretche': print(f'Asistente: {respuesta_chatbot(query_jauretche, pregunta, \"2\")}')\n",
        "\n",
        "\n",
        "\n",
        "      # CATEGORÍA = 3\n",
        "      # --> preguntas de información de instituciones / búsqueda tabular / base de datos tabular:\n",
        "      elif clasificacion_bdd_zero['labels'][0] == '3':\n",
        "\n",
        "        prompt_mayus = limpiar_prompt_mayus(pregunta)\n",
        "\n",
        "        # # ------------------------------------- Control de Filtro de Institución -------------------------------------------------------------\n",
        "        # # Descomentar para controlar como se formateó el prompt\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # print('Control de Filtro de Institución (Para BD Tabular)')\n",
        "        # print('')\n",
        "        # print(f'Prompt original: {pregunta}')\n",
        "        # print('')\n",
        "        # print(f'Prompt convertido a mayúsculas: {prompt_mayus}')\n",
        "        # print('')\n",
        "        # print('--------------------------------------------------------------------------')\n",
        "        # print('')\n",
        "        # # ---------------------------------- Fin control de Filtro de Institución  ------------------------------------------------------------\n",
        "\n",
        "        print(f'Asistente: {respuesta_chatbot(prompt_mayus, pregunta, \"3\")}')\n"
      ],
      "metadata": {
        "id": "p619v8LUwp7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Ejecución del Chatbot:"
      ],
      "metadata": {
        "id": "G9CE7n2Dw1I_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para invocar al chatbot, ejecutar el código siguiente (\"salir\" para finalizar)."
      ],
      "metadata": {
        "id": "tCC6IRkFw6-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot()"
      ],
      "metadata": {
        "id": "dzIjYaUfw2hR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}